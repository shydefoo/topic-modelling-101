{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import nltk\n",
    "\n",
    "from gensim.utils import simple_preprocess \n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "desktop = os.path.join(os.path.expanduser('~'), 'Desktop')\n",
    "large_file = os.path.join(desktop, 'large_file')\n",
    "processed_wiki_sub = os.path.join(large_file, 'processed_wiki_sub')\n",
    "text_path = os.path.join(processed_wiki_sub, 'processed_wiki.textaa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(text_path, 'r') as file:\n",
    "    text = file.read()\n",
    "line = text.split('\\n')\n",
    "df = pd.DataFrame(line, columns = ['article'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article    102100\n",
       "dtype: int64"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    '''\n",
    "    lemmatize text, without pos tag, lemmatizer treats every word as noun. pos='v' tells lemmatizer to treat \n",
    "    each word as verb.\n",
    "    '''\n",
    "    word = WordNetLemmatizer().lemmatize(text, pos='v')\n",
    "    return stemmer.stem(word)\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    # convert document into list of lowercase tokens, filter based on token length\n",
    "    for token in simple_preprocess(text):\n",
    "        if token not in STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df.iloc[0].values[0]\n",
    "sample = df.sample(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = df['article'].map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Build dictionary from processed docs. \n",
    "Dictionary example attributes: \n",
    "- token2id\n",
    "- id2token\n",
    "- dfs (token document frequency)\n",
    "'''\n",
    "dictionary = gensim.corpora.Dictionary(processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10):\n",
    "#     print(\"{} appears {} times\".format(dictionary.id2token[i], dictionary.dfs[i]))\n",
    "# dictionary.num_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Filter dictionary. \n",
    "- Remove tokens with dfs<15, more than 0.5 fraction of total corpus size, keep_n most frequent tokens\n",
    "'''\n",
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Gensim doc2bow\n",
    "For each document, create a bagofwords representation\n",
    "'''\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs] # bow rep for each article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LdaMulticore\n",
    "lda_model = LdaMulticore(bow_corpus, num_topics=100, id2word=dictionary, passes=2, workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model.show_topic(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = os.path.join(processed_wiki_sub,'processed_wiki.textab')\n",
    "with open(test_set, 'r') as file2:\n",
    "    text = file2.read()\n",
    "line = text.split('\\n')    \n",
    "df2 = pd.DataFrame(line, columns=['article'])\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_doc = df2.iloc[0]\n",
    "test_doc = test_doc['article']\n",
    "test_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_vector = dictionary.doc2bow(preprocess(test_doc))\n",
    "lda_model[bow_vector]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
